# ğŸ§  AI Ethics Fairness Audit â€” COMPAS Dataset

This project performs a fairness audit on the COMPAS recidivism prediction system using **IBM's AI Fairness 360 (AIF360)**. The goal is to identify, measure, and mitigate racial bias in automated risk assessment systems.

---

## ğŸ“Œ Project Objectives

- Analyze the COMPAS dataset for racial bias  
- Compute key fairness metrics  
- Visualize disparities between racial groups  
- Apply fairness mitigation techniques  
- Produce an ethics-grounded interpretation of results  

---

## ğŸ“‚ Project Structure

```
ğŸ“ root
â”œâ”€â”€ audit.ipynb          # Full fairness audit notebook
â”œâ”€â”€ report.pdf              # Written report (Part 1â€“4)
â”œâ”€â”€ data/                   # COMPAS dataset (if stored locally)
â”œâ”€â”€ README.md               # This file
```

---

## ğŸ› ï¸ Tools & Libraries

- **AIF360** â€” Bias detection & mitigation  
- **Pandas** â€” Data processing  
- **Matplotlib** â€” Visualizations  
- **Numpy** â€” Numerical operations  

---

## ğŸ“Š Fairness Metrics Computed

- **Disparate Impact**  
- **Mean Difference**  
- **False Positive Rate (FPR) Difference**  
- **Group-wise risk score comparison**  

---

## ğŸ§ª How to Run the Notebook

1. Install required libraries:

```bash
pip install aif360 pandas numpy matplotlib
```

2. Launch Jupyter Notebook:

```bash
jupyter notebook
```

3. Open `audit.ipynb` and run all cells.

---

## ğŸ¯ Key Findings (Summary)

- COMPAS exhibits **significant racial bias** against African-American defendants.
- **Disparate Impact < 0.8**, failing the 80% fairness rule.
- African-Americans face **much higher false positive rates**, meaning they are more often classified as "high risk" even when they do not reoffend.
- Bias mitigation using **Reweighing** improves fairness but does not fully eliminate disparities.

---

## ğŸ§© Ethical Principles Applied

- **Justice** â€” Ensuring fairness across demographic groups  
- **Non-maleficence** â€” Preventing harm caused by biased predictions  
- **Transparency** â€” Measuring algorithmic behavior  
- **Accountability** â€” Auditing and documenting bias  

---



